# 항해 6주차 과제

## 목차
[1. 배경](#1-배경)  
[2. 문제 해결](#2-문제-해결)  
[3. 테스트](#3-테스트)  
[4. 한계점](#4-한계점)  
[5. 결론](#5-결론)


# ✏️ 1. 배경

콘서트 예매 시스템에서 다음 두 기능의 성능 향상을 위해 캐싱 전략을 사용한다.

- **포인트 조회 / 충전** 기능은 사용자가 잦은 조회를 하지만 변경은 드물기 때문에 캐시를 통해 응답 속도를 개선할 수 있다.
- **콘서트 목록 조회**는 비교적 자주 바뀌지 않는 데이터이며, 유저 접속 시 자주 호출되기 때문에 캐싱 적합성이 높다.

이를 통해 불필요한 DB 조회를 줄이고 시스템 응답 속도를 높이고자 하였다.

## 📌  1.1 캐시 전략 비교

Memory Cache vs Redis Cache

| 항목 | **Memory Cache** | **Redis Cache** |
| --- | --- | --- |
| **위치** | 애플리케이션 내부 JVM 메모리 | 외부 Redis 서버 (독립 프로세스) |
| **속도** | 매우 빠름 (JVM 내 접근) | 빠름 (네트워크 IO 포함) |
| **확장성** | 단일 인스턴스 한정 | 여러 서버에서 공유 가능 (분산 캐시) |
| **데이터 공유** | 불가 (서버 간 캐시 공유 안 됨) | 가능 (여러 인스턴스 간 캐시 공유) |
| **영속성** | 서버 재시작 시 캐시 사라짐 | Redis는 설정에 따라 지속 가능 (RDB, AOF 등) |
| **사용 예** | 간단한 캐시, 로컬 계산 결과 저장 등 | 세션 관리, 인증 토큰, 분산 락, 조회 캐시 등 |
| **TTL 설정** | 수동으로 코드에 직접 구현 | TTL 지원, 만료 전략 다양함 |
| **데이터 용량 제한** | JVM 메모리 의존 (OutOfMemory 위험 존재) | 서버 리소스에 따라 유연하게 관리 가능 |
| **장애 허용성** | 서버 죽으면 캐시도 소멸 | Redis 클러스터로 장애 대응 가능 |

## 📌 1.2 캐싱 전략 선택 : **Redis Cache**

- **분산 환경**에서 여러 인스턴스가 동일한 캐시 데이터를 공유해야 함

  → Redis는 서버 간 **공유 캐시**가 가능하여 수평 확장이 용이함.

- **분산 락 처리** 필요 (예: 포인트 충전 동시성 제어)

  → Redisson을 활용한 **분산 락**은 Redis 기반에서만 가능.

- **TTL, 키 만료 전략** 등 유연한 캐시 관리 기능 필요

  → Redis는 **캐시 만료, TTL 설정**을 지원함.

- **재시작 후 캐시 복구 옵션**이 필요함

  → Redis는 설정에 따라 캐시 데이터를 디스크에 저장 가능함.


---

# ✏️ 2. 문제 해결

## 📌 2.1. 적용 전략

### 포인트 조회 / 충전

| 구분 | 전략 | 설명 |
| --- | --- | --- |
| 포인트 조회 | LookAside | `@Cacheable`을 사용하여 캐시 존재 시 Redis에서 바로 응답, 없으면 DB 조회 후 캐시 저장 |
| 포인트 충전 | WriteThrough | 충전 시 DB 업데이트와 함께 `@CacheEvict`로 캐시 만료 처리 |

### 콘서트 목록 조회

| 구분 | 전략 | 설명 |
| --- | --- | --- |
| 콘서트 목록 조회 | LookAside | 조회 시 캐시에 존재하면 바로 반환하고, 없으면 DB 조회 후 캐싱 |

## 📌 2.2. 캐시 설정

- 캐시 TTL은 `CacheTtlRegistry` 클래스를 통해 분리하고, `enum`으로 관리하여 확장성과 가독성 확보.
- `GenericJackson2JsonRedisSerializer`를 사용해 JSON 직렬화로 Redis에 저장.

```java
@Configuration
@EnableCaching
public class RedisCacheConfig {

    private final CacheTtlRegistry cacheTtlRegistry;

    public RedisCacheConfig(CacheTtlRegistry cacheTtlRegistry) {
        this.cacheTtlRegistry = cacheTtlRegistry;
    }

    @Bean
    public RedisCacheManager redisCacheManager(RedisConnectionFactory connectionFactory) {

        RedisSerializationContext.SerializationPair<String> stringSerializer = RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer());
        RedisSerializationContext.SerializationPair<Object> jsonSerializer = RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer());

        Map<String, RedisCacheConfiguration> cacheConfigs = new HashMap<>();
        for (CacheName cacheName : CacheName.values()) {
            cacheConfigs.put(
                    cacheName.getName(),
                    RedisCacheConfiguration.defaultCacheConfig()
                            .entryTtl(cacheTtlRegistry.getTtlFor(cacheName.getName()))
                            .serializeKeysWith(stringSerializer)
                            .serializeValuesWith(jsonSerializer)
            );
        }

        RedisCacheConfiguration defaultConfig = RedisCacheConfiguration.defaultCacheConfig()
                .entryTtl(Duration.ofMinutes(10))
                .serializeKeysWith(stringSerializer)
                .serializeValuesWith(jsonSerializer);

        return RedisCacheManager
                .builder(connectionFactory)
                .cacheDefaults(defaultConfig)
                .withInitialCacheConfigurations(cacheConfigs)
                .build();
    }
}

@Component
public class CacheTtlRegistry {

    public Duration getTtlFor(String cacheName) {

        for (CacheName cache : CacheName.values()) {
            if (cache.getName().equals(cacheName)) {
                return cache.getTtl();
            }
        }
        return Duration.ofMinutes(10); // default TTL 10분
    }
}

public enum CacheName {

    CONCERT_CACHE("concertCache", Duration.ofMinutes(60)),
    USER_POINT("userPoint", Duration.ofMinutes(10));

    private final String name;
    private final Duration ttl;

    CacheName(String name, Duration ttl) {
        this.name = name;
        this.ttl = ttl;
    }

    public String getName() {
        return name;
    }

    public Duration getTtl() {
        return ttl;
    }
}
```

---

# ✏️ 3. 테스트

## 📌 3.1. 콘서트

- **콘서트 목록 API**: 최초 요청 시 DB 접근 후 Redis에 저장됨을 확인, 이후 요청은 Redis에서 조회됨.
  - 캐시 조회 시 6395ms → 9ms 로 성능 확연하게 개선
  - [콘서트 조회](콘서트_조회_캐싱.png)


## 📌 3.2. 포인트

- **포인트 조회 API**: 포인트 충전 전까지 Redis에서 조회되며, 충전 시점에 캐시가 명시적으로 만료됨을 확인.
  - 캐시 조회 시 175ms → 11ms 로 성능 확연하게 개선
  - [포인트_조회](포인트_조회_캐싱.png)


- **포인트 충전 API** : 포인트 충전 시 캐시 만료 처리됨을 확인. (재조회 시 DB에서 조회됨)
  - [포인트_충전](포인트_충전_캐싱.png)

---

# ✏️ 4. 한계점

## 📌 4.1. 실시간 데이터의 캐싱 전략 한계

좌석 수와 같은 실시간 데이터는 사용자의 행동(예약, 취소 등)에 따라 **순간적으로 변동되는 값**이며, 시스템 내에서 **강한 일관성**이 요구되는 대표적인 케이스입니다. 이 데이터를 Redis 캐시에 저장하고 일정 시간 동안 유지하는 방식은 다음과 같은 위험을 동반합니다.

- **데이터 불일치**: 캐시에 저장된 좌석 정보가 최신 상태를 반영하지 못할 수 있으며, 이로 인해 이미 예약된 좌석을 또 다른 사용자에게 보여주는 등의 문제가 발생할 수 있습니다.
- **경쟁 조건**: 다수의 사용자가 동시에 예약을 시도할 경우, 캐시가 반영되지 않아 동일한 좌석에 중복 예약 요청이 발생할 수 있습니다.
- **갱신 부담**: 실시간으로 캐시를 갱신하는 작업은 오히려 Redis에 과도한 부하를 유발하고, DB보다 안정적이지 않은 상태로 데이터를 제공하게 될 가능성이 있습니다.
- **트랜잭션 일관성 부족**: DB 트랜잭션 내에서의 좌석 처리 로직과 Redis 캐시 갱신 로직을 완전히 동기화하기 어렵기 때문에, **ACID** 원칙을 깨뜨릴 위험이 있습니다.

실시간성이 요구되는 데이터(예약 가능 좌석 수 등)는 캐시가 아닌 **DB 직접 조회와 트랜잭션 제어**를 통해 일관성을 유지하는 방식이 적절합니다. 캐시는 **변경 빈도가 낮고 조회 빈도가 높은 데이터**에 국한하여 적용하는 것이 시스템의 안정성과 정확성을 보장하는 방향입니다.

## 📌 4.2. Cache Stampede 문제

- 캐시 스탬피드(Cache Stampede)는 **같은 키에 대한 캐시가 만료되었을 때**, 다수의 요청이 동시에 캐시가 아닌 **DB 또는 원본 데이터 소스**로 쏠리는 현상을 말합니다.

예시 상황)

1. `concert:list:all` 데이터가 Redis에 TTL 10분으로 저장됨.
2. 10분 뒤 해당 키가 만료됨.
3. 동시에 수백~수천 개의 요청이 콘서트 목록을 요청함.
4. 캐시에 아무것도 없으므로 모든 요청이 DB로 향함.
5. **DB 과부하** 발생 → 성능 저하, 장애로 이어질 수 있음.

해결 방법)

| 전략 | 설명 |
| --- | --- |
| **Mutex(분산 락)** | 첫 번째 요청만 DB를 조회하고 나머지는 대기하거나 캐시 조회 재시도 (Redisson 분산락 등 활용) |
| **Cache Prewarming(사전 로딩)** | 캐시가 만료되기 전에 백그라운드 스레드가 미리 캐시를 갱신 |
| **TTL+Jitter** | TTL에 소량의 랜덤값을 더해 각 키의 만료 시점을 분산 |
| **Request Coalescing** | 동일한 키 요청을 하나로 합쳐 처리하고 결과를 모든 요청자에게 전달 (복잡한 구현 필요) |

---

# ✏️ 5. 결론

- Redis 캐시 적용을 통해 주요 API 응답 속도 향상 및 DB 부하 감소 효과를 확인함.
- 캐시 전략(LookAside, WriteThrough)을 각 기능 특성에 맞게 적절히 분리하여 적용함.
- TTL 정책은 Config 클래스와 Enum 기반의 Registry로 관리하여 유지보수성을 높일 수 있음.
- 서비스 계층에 캐시 어노테이션을 일관되게 적용하여 책임 분리 원칙 따름.



[캐시 전략 및 성능 개선 보고서 notion](https://www.notion.so/teamsparta/6-1e52dc3ef51480b2b1e2f5afd4f09bfb#1e52dc3ef5148052b204e7b56cecefef)
